# -*- snakemake -*-
import os
import re
import csv
from snakemakelib.config import update_sml_config, get_sml_config
from snakemakelib.utils import utc_time
#from snakemakelib.log import LoggerManager
import logging

#smllogger = LoggerManager().getLogger(__name__)
smllogger = logging.getLogger(__name__)

include: '../settings.rules'
include: '../../../settings.rules'

cfg = get_sml_config("settings")

config_default = {
    'settings' : {
        'temp_rules_default' : list(set(['sratools_prefetch'] + cfg['temp_rules_default'])),
    },
    "bio.ngs.tools.sratools" : {
        "email" : os.getenv("USER_EMAIL", None),
        "srastudy" : "",
        "retmax" : 500,
        "tracearchive" : "http://trace.ncbi.nlm.nih.gov/Traces/sra/",
        "workspacelocation" : os.getenv("NCBI_HOME", os.path.join(os.getenv("HOME"), "ncbi/public")),
        "_datadir" : os.curdir,
        "_run2sample" : {},
        "_metadata" : [],
        "fastq-dump" : {
            'cmd' : "fastq-dump",
            "options" : "--split-3 -F",
        },
        "prefetch" : {
            'cmd' : "prefetch",
            "options" : "",
        },
        'options' : "",
    },
}

update_sml_config(config_default)

sra_cfg = get_sml_config('bio.ngs.tools.sratools')
ngs_cfg = get_sml_config('bio.ngs.settings')

rule sratools_download_srastudy_metadata:
    """Download srastudy metadata."""
    params: traces = sra_cfg['tracearchive']
    output: csv = "{prefix}_info.csv"
    run:
        shell ("wget -O {output}  '{traces}sra.cgi?save=efetch&db=sra&rettype=runinfo&term={basename}'".format(output=output.csv, traces=params.traces, basename=os.path.basename(wildcards.prefix)))

rule sratools_download_srastudy_biosample:
    input: metadata = "{prefix}_info.csv"
    output: csv = "{prefix}_biosample.csv"
    run:
        with open(input.metadata, "r") as fh:
            reader = csv.DictReader(fh)
            bioproject = list(set([x["BioProject"] for x in reader]))
        if len(bioproject) > 1:
            smllogger.warn("More than one bioproject defined! This may or may not be ok, depending on what you're doing")
        with open(output.csv, "w") as fh:
            if sra_cfg['email'] is None:
                s = "bio.ngs.tools.sratools: No email set; must tell NCBI mail address! Either set USER_EMAIL environment variable or configuration variable bio.ngs.tools.sratools.email"
                smllogger.warn(s)
                fh.write(s)
            else:
                from Bio import Entrez
                import xml.etree.ElementTree as ET
                Entrez.email = sra_cfg['email']
                smllogger.info("Connecting to Entrez; querying for bioproject {bioprj}".format(bioprj=bioproject[0]))
                handle = Entrez.esearch(db="sra", term=bioproject[0], retmax=sra_cfg['retmax'])
                record = Entrez.read(handle)
                handle.close()
                smllogger.info("Retrieved biosample id list for bioproject {bioprj}; fetching biosamples".format(bioprj=bioproject[0]))
                handle = Entrez.efetch(db="sra", id=record['IdList'])
                record = handle.read()
                handle.close()
                smllogger.info("Retrieved biosample info; parsing xml")
                tree = ET.fromstring(record)
                record_list = []
                fieldnames = []
                for sample in tree.findall('.//SAMPLE'):
                    d = sample.attrib
                    title = sample.findall(".//TITLE")
                    d.update({'title':title[0].text})
                    d.update({k.text:v.text for (k,v) in zip(sample.findall(".//TAG"), sample.findall(".//VALUE"))})
                    fieldnames = list(set(fieldnames + list(d.keys())))
                    record_list.append(d)
                writer = csv.DictWriter(fh, fieldnames=fieldnames)
                writer.writeheader()
                for r in record_list:
                    writer.writerow(r)
                

rule sratools_prefetch:
    """Run sratools prefetch"""
    params: cmd = sra_cfg['prefetch']['cmd'],
            options = sra_cfg['prefetch']['options']
    output: temp(os.path.join(sra_cfg['workspacelocation'], "sra", os.path.basename("{prefix}") + ".sra"))
    log: os.path.join(sra_cfg['workspacelocation'], "sra", "{prefix}.log")
    shell: "{params.cmd} {params.options} $(basename {wildcards.prefix})"

def _sra_file(wildcards):
    return os.path.join(sra_cfg['workspacelocation'], "sra", os.path.basename(wildcards.prefix) + ".sra")

rule sratools_fastq_dump:
    """Run sratools fastq-dump"""
    params: cmd = sra_cfg['fastq-dump']['cmd'],
            options = " ".join([sra_cfg['fastq-dump']['options'],
                                '--gzip' if ngs_cfg["fastq_suffix"].endswith(".gz") else '',
                                '--bzip2' if ngs_cfg["fastq_suffix"].endswith(".bzip2") else ''])
    input: _sra_file
    # Disable . and _ in sra file name
    output: read1 = "{prefix,[A-Za-z0-9]+}" + ngs_cfg["read1_label"] + ngs_cfg["fastq_suffix"],
            read2 = "{prefix,[A-Za-z0-9]+}" + ngs_cfg["read2_label"] + ngs_cfg["fastq_suffix"]
    shell: "{params.cmd} {params.options} -O $(dirname {wildcards.prefix}) $(basename {wildcards.prefix})"

def _get_run(wildcards):
    tmp = wildcards.prefix.split("_")
    if len (tmp) == 1:
        run = tmp[0]
    else:
        (_, run) = tmp
    return os.path.join(sra_cfg['_datadir'], "{run}_{read}".format(run=run, read=wildcards.read) + ngs_cfg["fastq_suffix"])

rule sratools_link_sra_fastq:
    """Link sra run fastq file from download directory to output path"""
    input: fastq = _get_run
    output: fastq = os.path.join("{path}", "{prefix}" + "_{read}" + ngs_cfg["fastq_suffix"])
    shell: "ln -s {input.fastq} {output.fastq}"

ruleorder: sratools_link_sra_fastq > sratools_fastq_dump
