# -*- snakemake -*-
import os
import re
import csv
from snakemakelib.config import update_snakemake_config
from snakemakelib.utils import utc_time
from snakemakelib.log import LoggerManager

smllogger = LoggerManager().getLogger('bio/ngs/tools/sratools.rules')

include: '../settings.rules'
include: '../../../settings.rules'

config_default = {
    'settings' : {
        'temp_rules_default' : list(set(['sratools_prefetch'] + config['settings']['temp_rules_default'])),
    },
    "bio.ngs.tools.sratools" : {
        "email" : os.getenv("USER_EMAIL", None),
        "srastudy" : "",
        "retmax" : 500,
        "tracearchive" : "http://trace.ncbi.nlm.nih.gov/Traces/sra/",
        "workspacelocation" : os.getenv("NCBI_HOME", os.path.join(os.getenv("HOME"), "ncbi/public")),
        "_datadir" : os.curdir,
        "_run2sample" : {},
        "_metadata" : [],
        "fastq-dump" : {
            'cmd' : "fastq-dump",
            "options" : "--split-3 -F",
        },
        "prefetch" : {
            'cmd' : "prefetch",
            "options" : "",
        },
        'options' : "",
    },
}

config = update_snakemake_config(config, config_default)

sra_cfg = config['bio.ngs.tools.sratools']
ngs_cfg = config['bio.ngs.settings']

rule sratools_compile_srastudy_metadata:
    """Combine output from rules below"""
    input: metadata = "{prefix}_metadata.csv",
           biosample = "{prefix}_biosample.csv"
    output: csv = "{prefix}_info.csv"
    run:
        with open(input.metadata, "r") as fh:
            md_reader = csv.DictReader(fh.readlines())
        with open(input.biosample, "r") as fh:
            bio_reader = csv.DictReader(fh.readlines())
        with open(output.csv, "w") as fh:
            fieldnames = md_reader.fieldnames + bio_reader.fieldnames
            writer = csv.DictWriter(fh, fieldnames=fieldnames)
            writer.writeheader()
            for (md, bio) in zip(md_reader, bio_reader):
                md.update(bio)
                writer.writerow(md)

rule sratools_download_srastudy_metadata:
    """Download srastudy metadata."""
    params: traces = sra_cfg['tracearchive']
    output: csv = "{prefix}_metadata.csv"
    run:
        shell ("wget -O {output}  '{traces}sra.cgi?save=efetch&db=sra&rettype=runinfo&term={basename}'".format(output=output.csv, traces=params.traces, basename=os.path.basename(wildcards.prefix)))

rule sratools_download_srastudy_biosample:
    input: metadata = "{prefix}_metadata.csv"
    output: csv = "{prefix}_biosample.csv"
    run:
        with open(input.metadata, "r") as fh:
            reader = csv.DictReader(fh)
            bioproject = list(set([x["BioProject"] for x in reader]))
        if len(bioproject) > 1:
            smllogger.warn("More than one bioproject defined! This may or may not be ok, depending on what you're doing")
        if sra_cfg['email'] is None:
            s = "bio.ngs.tools.sratools: No email set; must tell NCBI mail address! Either set USER_EMAIL environment variable or configuration variable bio.ngs.tools.sratools.email"
            smllogger.warn(s)
        else:
            with open(output.csv, "w") as fh:
                from Bio import Entrez
                import xml.etree.ElementTree as ET
                Entrez.email = sra_cfg['email']
                smllogger.info("Connecting to Entrez; querying for bioproject {bioprj}".format(bioprj=bioproject[0]))
                handle = Entrez.esearch(db="sra", term=bioproject[0], retmax=sra_cfg['retmax'])
                record = Entrez.read(handle)
                handle.close()
                smllogger.info("Retrieved biosample id list for bioproject {bioprj}; fetching biosamples".format(bioprj=bioproject[0]))
                handle = Entrez.efetch(db="sra", id=record['IdList'])
                record = handle.read()
                handle.close()
                smllogger.info("Retrieved biosample info; parsing xml")
                tree = ET.fromstring(record)
                record_list = []
                fieldnames = []
                for sample in tree.findall('.//SAMPLE'):
                    d = sample.attrib
                    title = sample.findall(".//TITLE")
                    d.update({'title':title[0].text})
                    d.update({k.text:v.text for (k,v) in zip(sample.findall(".//TAG"), sample.findall(".//VALUE"))})
                    fieldnames = list(set(fieldnames + list(d.keys())))
                    record_list.append(d)
                writer = csv.DictWriter(fh, fieldnames=fieldnames)
                writer.writeheader()
                for r in record_list:
                    writer.writerow(r)
                

rule sratools_prefetch:
    """Run sratools prefetch"""
    params: cmd = sra_cfg['prefetch']['cmd'],
            options = sra_cfg['prefetch']['options']
    output: temp(os.path.join(sra_cfg['workspacelocation'], "sra", os.path.basename("{prefix}") + ".sra"))
    log: os.path.join(sra_cfg['workspacelocation'], "sra", "{prefix}.log")
    shell: "{params.cmd} {params.options} $(basename {wildcards.prefix}) > {log}"

def _sra_file(wildcards):
    return os.path.join(sra_cfg['workspacelocation'], "sra", os.path.basename(wildcards.prefix) + ".sra")

rule sratools_fastq_dump:
    """Run sratools fastq-dump"""
    params: cmd = sra_cfg['fastq-dump']['cmd'],
            options = " ".join([sra_cfg['fastq-dump']['options'],
                                '--gzip' if ngs_cfg["fastq_suffix"].endswith(".gz") else '',
                                '--bzip2' if ngs_cfg["fastq_suffix"].endswith(".bzip2") else ''])
    input: _sra_file
    # Disable . and _ in sra file name
    output: read1 = os.path.join("{path}", "{prefix,[A-Za-z0-9]+}" + ngs_cfg["read1_label"] + ngs_cfg["fastq_suffix"]),
            read2 = os.path.join("{path}", "{prefix,[A-Za-z0-9]+}" + ngs_cfg["read2_label"] + ngs_cfg["fastq_suffix"])
    shell: "{params.cmd} {params.options} -O {wildcards.path} {wildcards.prefix}"

def _get_run(wildcards):
    run = ngs_cfg['sampleorg'].raw_run_re.parse(os.path.join(wildcards.path, wildcards.prefix))['PU']
    return os.path.join(sra_cfg['_datadir'], "{run}_{read}".format(run=run, read=wildcards.read) + ngs_cfg["fastq_suffix"])

rule sratools_link_sra_fastq:
    """Link sra run fastq file from download directory to output path"""
    input: fastq = _get_run
    output: fastq = os.path.join("{path}", "{prefix,[A-Za-z0-9]+}" + "_{read,([0-9]+|R[0-9]+)}" + ngs_cfg["fastq_suffix"])
    shell: "ln -fs {input.fastq} {output.fastq}"

ruleorder: sratools_link_sra_fastq > sratools_fastq_dump
